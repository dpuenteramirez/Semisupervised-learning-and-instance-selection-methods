{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Â«Friedman TestÂ» from Demsar (2006)\n",
    "Adapted from cgosorio's work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import scipy.stats\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from autorank import autorank, plot_stats, create_report, latex_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float_kind': \"{:6.3f}\".format})\n",
    "#np.set_printoptions(precision=4)\n",
    "RED='\\033[0;31m'\n",
    "GRN='\\033[0;32m'\n",
    "NC='\\033[0m'\n",
    "BLD='\\033[1m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metric = 'accuracy score'\n",
    "results_path = os.path.join('ranks', 'results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base estimators used: ['KNeighborsClassifier' 'DecisionTreeClassifier' 'GaussianNB']\n",
      "Filters used: ['ENN' 'LSSm' 'ENANE' 'base']\n",
      "Percents labeled used: [ 0.050  0.100  0.150  0.200  0.250  0.300  0.350]\n",
      "# Datasets used: 18\n"
     ]
    }
   ],
   "source": [
    "filters = results_df['filter'].unique()\n",
    "base_estimators = results_df['base'].unique()\n",
    "percents_labeled = results_df['percent labeled'].unique()\n",
    "datasets = results_df['dataset'].unique()\n",
    "percents_labeled.sort()\n",
    "\n",
    "print(f\"Base estimators used: {base_estimators}\")\n",
    "print(f\"Filters used: {filters}\")\n",
    "print(f\"Percents labeled used: {percents_labeled}\")\n",
    "print(f\"# Datasets used: {len(datasets)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs of base estimator with filters:\n",
      " [['KNeighborsClassifier' 'ENN']\n",
      " ['KNeighborsClassifier' 'LSSm']\n",
      " ['KNeighborsClassifier' 'ENANE']\n",
      " ['KNeighborsClassifier' 'base']\n",
      " ['DecisionTreeClassifier' 'ENN']\n",
      " ['DecisionTreeClassifier' 'LSSm']\n",
      " ['DecisionTreeClassifier' 'ENANE']\n",
      " ['DecisionTreeClassifier' 'base']\n",
      " ['GaussianNB' 'ENN']\n",
      " ['GaussianNB' 'LSSm']\n",
      " ['GaussianNB' 'ENANE']\n",
      " ['GaussianNB' 'base']]\n"
     ]
    }
   ],
   "source": [
    "grouped_df = results_df.groupby(['dataset', 'percent labeled',\n",
    "                                              'base', 'filter']).mean()\n",
    "\n",
    "grouped_df = grouped_df[metric].to_frame()\n",
    "grouped_df.reset_index(inplace=True)\n",
    "\n",
    "bases_filters = np.array(list(product(base_estimators, filters)))\n",
    "print(\"Pairs of base estimator with filters:\\n\", bases_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    dataset  percent labeled                    base filter  \\\n",
      "0          BreastTissue.csv             0.05  DecisionTreeClassifier  ENANE   \n",
      "1          BreastTissue.csv             0.05  DecisionTreeClassifier    ENN   \n",
      "2          BreastTissue.csv             0.05  DecisionTreeClassifier   LSSm   \n",
      "3          BreastTissue.csv             0.05  DecisionTreeClassifier   base   \n",
      "4          BreastTissue.csv             0.05              GaussianNB  ENANE   \n",
      "...                     ...              ...                     ...    ...   \n",
      "1507  wifi-localization.csv             0.35              GaussianNB   base   \n",
      "1508  wifi-localization.csv             0.35    KNeighborsClassifier  ENANE   \n",
      "1509  wifi-localization.csv             0.35    KNeighborsClassifier    ENN   \n",
      "1510  wifi-localization.csv             0.35    KNeighborsClassifier   LSSm   \n",
      "1511  wifi-localization.csv             0.35    KNeighborsClassifier   base   \n",
      "\n",
      "      accuracy score  \n",
      "0           0.247273  \n",
      "1           0.262727  \n",
      "2           0.260909  \n",
      "3           0.319091  \n",
      "4           0.225455  \n",
      "...              ...  \n",
      "1507        0.031000  \n",
      "1508        0.028500  \n",
      "1509        0.030500  \n",
      "1510        0.028500  \n",
      "1511        0.032000  \n",
      "\n",
      "[1512 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def base_filter_values():\n",
    "    values = pd.DataFrame()\n",
    "    for base_filter in bases_filters:\n",
    "        base_, filter_ = base_filter\n",
    "        working_df = grouped_df.loc[\n",
    "            (grouped_df['percent labeled'] == percent) &\n",
    "            (grouped_df['base'] == base_) &\n",
    "            (grouped_df['filter'] == filter_)\n",
    "            ]\n",
    "        value = working_df[metric].to_frame()\n",
    "        value.reset_index(inplace=True, drop=True)\n",
    "        value.columns = [':'.join(base_filter)]\n",
    "        values = pd.concat((value, values), axis=1)\n",
    "\n",
    "    return values\n",
    "\n",
    "\n",
    "def split_onto_base_estimators():\n",
    "    for base_ in base_estimators:\n",
    "        df = curr_vals.filter(regex=base_)\n",
    "        base_dfs.append(df)\n",
    "    \n",
    "    return base_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "> Percent labeled:  0.05\n",
      "\n",
      "KNeighborsClassifier:base 2.39\n",
      "KNeighborsClassifier:ENANE 2.28\n",
      "KNeighborsClassifier:LSSm 2.67\n",
      "KNeighborsClassifier:ENN 2.67\n",
      "\n",
      "DecisionTreeClassifier:base 2.33\n",
      "DecisionTreeClassifier:ENANE 2.86\n",
      "DecisionTreeClassifier:LSSm 2.17\n",
      "DecisionTreeClassifier:ENN 2.64\n",
      "\n",
      "GaussianNB:base 2.19\n",
      "GaussianNB:ENANE 2.22\n",
      "GaussianNB:LSSm 2.81\n",
      "GaussianNB:ENN 2.78\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "> Percent labeled:  0.1\n",
      "\n",
      "KNeighborsClassifier:base 2.83\n",
      "KNeighborsClassifier:ENANE 2.72\n",
      "KNeighborsClassifier:LSSm 2.25\n",
      "KNeighborsClassifier:ENN 2.19\n",
      "\n",
      "DecisionTreeClassifier:base 2.83\n",
      "DecisionTreeClassifier:ENANE 2.28\n",
      "DecisionTreeClassifier:LSSm 2.36\n",
      "DecisionTreeClassifier:ENN 2.53\n",
      "\n",
      "GaussianNB:base 3.22\n",
      "GaussianNB:ENANE 2.17\n",
      "GaussianNB:LSSm 2.19\n",
      "GaussianNB:ENN 2.42\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "> Percent labeled:  0.15\n",
      "\n",
      "KNeighborsClassifier:base 2.25\n",
      "KNeighborsClassifier:ENANE 2.47\n",
      "KNeighborsClassifier:LSSm 2.92\n",
      "KNeighborsClassifier:ENN 2.36\n",
      "\n",
      "DecisionTreeClassifier:base 2.61\n",
      "DecisionTreeClassifier:ENANE 2.53\n",
      "DecisionTreeClassifier:LSSm 2.17\n",
      "DecisionTreeClassifier:ENN 2.69\n",
      "\n",
      "GaussianNB:base 2.39\n",
      "GaussianNB:ENANE 2.50\n",
      "GaussianNB:LSSm 2.56\n",
      "GaussianNB:ENN 2.56\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "> Percent labeled:  0.2\n",
      "\n",
      "KNeighborsClassifier:base 2.50\n",
      "KNeighborsClassifier:ENANE 2.72\n",
      "KNeighborsClassifier:LSSm 2.86\n",
      "KNeighborsClassifier:ENN 1.92\n",
      "\n",
      "DecisionTreeClassifier:base 2.50\n",
      "DecisionTreeClassifier:ENANE 2.19\n",
      "DecisionTreeClassifier:LSSm 2.28\n",
      "DecisionTreeClassifier:ENN 3.03\n",
      "\n",
      "GaussianNB:base 2.47\n",
      "GaussianNB:ENANE 2.36\n",
      "GaussianNB:LSSm 2.53\n",
      "GaussianNB:ENN 2.64\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "> Percent labeled:  0.25\n",
      "\n",
      "KNeighborsClassifier:base 2.53\n",
      "KNeighborsClassifier:ENANE 2.22\n",
      "KNeighborsClassifier:LSSm 2.58\n",
      "KNeighborsClassifier:ENN 2.67\n",
      "\n",
      "DecisionTreeClassifier:base 2.58\n",
      "DecisionTreeClassifier:ENANE 2.33\n",
      "DecisionTreeClassifier:LSSm 2.11\n",
      "DecisionTreeClassifier:ENN 2.97\n",
      "\n",
      "GaussianNB:base 2.53\n",
      "GaussianNB:ENANE 2.75\n",
      "GaussianNB:LSSm 2.06\n",
      "GaussianNB:ENN 2.67\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "> Percent labeled:  0.3\n",
      "\n",
      "KNeighborsClassifier:base 2.33\n",
      "KNeighborsClassifier:ENANE 2.78\n",
      "KNeighborsClassifier:LSSm 2.56\n",
      "KNeighborsClassifier:ENN 2.33\n",
      "\n",
      "DecisionTreeClassifier:base 2.17\n",
      "DecisionTreeClassifier:ENANE 2.69\n",
      "DecisionTreeClassifier:LSSm 2.75\n",
      "DecisionTreeClassifier:ENN 2.39\n",
      "\n",
      "GaussianNB:base 2.83\n",
      "GaussianNB:ENANE 1.97\n",
      "GaussianNB:LSSm 2.94\n",
      "GaussianNB:ENN 2.25\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "> Percent labeled:  0.35\n",
      "\n",
      "KNeighborsClassifier:base 2.44\n",
      "KNeighborsClassifier:ENANE 2.47\n",
      "KNeighborsClassifier:LSSm 2.67\n",
      "KNeighborsClassifier:ENN 2.42\n",
      "\n",
      "DecisionTreeClassifier:base 2.42\n",
      "DecisionTreeClassifier:ENANE 2.69\n",
      "DecisionTreeClassifier:LSSm 2.53\n",
      "DecisionTreeClassifier:ENN 2.36\n",
      "\n",
      "GaussianNB:base 2.33\n",
      "GaussianNB:ENANE 2.22\n",
      "GaussianNB:LSSm 2.97\n",
      "GaussianNB:ENN 2.47\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for percent in percents_labeled:\n",
    "    curr_vals = base_filter_values()\n",
    "\n",
    "    base_dfs = list()\n",
    "    split_onto_base_estimators()\n",
    "    print('\\n\\n------------------------------------\\n\\n> Percent labeled: ',\n",
    "          percent)\n",
    "    for base, df in zip(base_estimators, base_dfs):\n",
    "        metric_vals = df.to_numpy()\n",
    "\n",
    "        N, k = len(datasets), len(df.columns)\n",
    "        assert N==metric_vals.shape[0] and k==metric_vals.shape[1]\n",
    "        \n",
    "        rankings = scipy.stats.rankdata(-metric_vals, axis=1)\n",
    "\n",
    "        Rj = average_ranks = np.mean(rankings, axis=0)\n",
    "\n",
    "        average_rank_tuples = sorted(zip(df.columns, average_ranks), key=lambda\n",
    "            a: a[1])\n",
    "        \n",
    "        average_rank_for = {method: value for method,\n",
    "                                              value in zip(df.columns,\n",
    "                                                           average_ranks)}\n",
    "        print()\n",
    "        for key, value in average_rank_for.items():\n",
    "            print(key, f'{value:.2f}')\n",
    "            \n",
    "            \n",
    "        part0 = (12*N)/(k*(k+1))\n",
    "        part1 = sum([Rj**2 for Rj in average_ranks])\n",
    "        part2 = (k*(k+1)**2)/4     \n",
    "        ð›˜2_F = part0*(part1-part2)\n",
    "        F_F = (N-1)*ð›˜2_F/(N*(k-1)-ð›˜2_F)\n",
    "        \n",
    "        data.append([percent, F_F, average_rank_for, N, k])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ivan And Davenport \n",
    "F_F = (N-1)*ð›˜2_F/(N*(k-1)-ð›˜2_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.statology.org/f-distribution-calculator/\n",
    "\n",
    "With 3 classifiers, 3 filters and the base one, and 18 data sets, $F_F$ is distributed according to the $F$ distribution with\n",
    "$7-1=6$ and $(7-1)Ã—(18âˆ’1)=102$ degrees of freedom. The critical value of $F(6,102)$ for $\\alpha=0.05$\n",
    "is $2.00002$, so we reject the null-hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using critical values\n",
    "#### FROM: https://stackoverflow.com/questions/39813470/f-test-with-python-finding-the-critical-value\n",
    "#### SEE ALSO: https://www.statology.org/f-critical-value-python/\n",
    "alpha = 0.05\n",
    "for percent, F_F, average_rank_for, N, k in data:\n",
    "    critical_value = scipy.stats.f.ppf(q=1-alpha, dfn=(k-1), dfd=(k-1)*(N-1))\n",
    "\n",
    "    if F_F > critical_value:\n",
    "        print(f\"{GRN}We reject the null-hypothesis, as the F_F value ({F_F:.3}) is greater than the critical value ({critical_value:.3})\")\n",
    "        print(f\"{BLD}That means that there are statistically differences between classifiers{NC}\")\n",
    "    else:\n",
    "        print(f\"{RED}We CAN NOT reject the null-hypothesis, as the F_F value ({F_F:.3}) is less than the critical value ({critical_value:.3})\")\n",
    "        print(f\"{BLD}That means that there are not statistically differences between classifiers{NC}\")\n",
    "        #print(f\"Or that the test is not powerfull enough to detect the differences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Autoranking\n",
    "\n",
    "Usage of the autoranking library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_col = np.array([[x] for _ in range(len(filters)) for x in datasets])\n",
    "\n",
    "for percent in percents_labeled:\n",
    "    curr_vals = base_filter_values()\n",
    "    base_dfs = list()\n",
    "    split_onto_base_estimators()\n",
    "    for base_ in base_dfs:\n",
    "        base_name = base_.keys()[0].split(':')[0]\n",
    "        bases_col = [x for x in base_.keys() for _ in range(len(base_))]\n",
    "        base_.columns = list(range(len(base_.keys())))\n",
    "        metric_data = base_.to_numpy()\n",
    "        raveled = np.ravel(metric_data)\n",
    "        \n",
    "        df_to_save = pd.DataFrame()\n",
    "        df_to_save['classifier_name'] = bases_col\n",
    "        df_to_save['dataset_name'] = datasets_col\n",
    "        df_to_save[metric] = raveled\n",
    "\n",
    "        df_to_save.to_csv(os.path.join('mean_ranks', '_'.join([str(percent), base_name])+'.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[           0         1         2         3\n",
       " 0   0.650000  0.615455  0.635455  0.623636\n",
       " 1   0.747077  0.774000  0.766615  0.759231\n",
       " 2   0.650000  0.600000  0.662500  0.587500\n",
       " 3   0.812766  0.814894  0.808511  0.817021\n",
       " 4   0.745964  0.735405  0.742000  0.762072\n",
       " 5   0.005405  0.002703  0.002703  0.008183\n",
       " 6   0.204545  0.229947  0.216934  0.073529\n",
       " 7   0.093939  0.116450  0.107359  0.098268\n",
       " 8   0.800000  0.795238  0.809524  0.795238\n",
       " 9   0.169930  0.181531  0.147633  0.158065\n",
       " 10  0.794921  0.834683  0.803254  0.817698\n",
       " 11  0.407600  0.405250  0.408150  0.406400\n",
       " 12  0.205630  0.231345  0.205798  0.257395\n",
       " 13  0.966508  0.966907  0.965840  0.967441\n",
       " 14  0.020062  0.019907  0.021928  0.021617\n",
       " 15  0.755000  0.735714  0.683571  0.698571\n",
       " 16  0.059091  0.054545  0.047727  0.052273\n",
       " 17  0.032000  0.028500  0.028500  0.030500,\n",
       "            0         1         2         3\n",
       " 0   0.583636  0.583636  0.595455  0.500000\n",
       " 1   0.747692  0.704308  0.747692  0.770308\n",
       " 2   0.675000  0.650000  0.637500  0.700000\n",
       " 3   0.780851  0.772340  0.765957  0.761702\n",
       " 4   0.720486  0.710054  0.712667  0.707189\n",
       " 5   0.010886  0.005405  0.010961  0.008108\n",
       " 6   0.073886  0.126738  0.053565  0.267201\n",
       " 7   0.122078  0.150000  0.122294  0.108225\n",
       " 8   0.833333  0.804762  0.852381  0.857143\n",
       " 9   0.183548  0.187230  0.183285  0.188778\n",
       " 10  0.843571  0.863175  0.849286  0.828810\n",
       " 11  0.414850  0.413750  0.416750  0.415500\n",
       " 12  0.165378  0.249076  0.180000  0.190840\n",
       " 13  0.909260  0.906993  0.903656  0.910730\n",
       " 14  0.031571  0.033748  0.036236  0.031571\n",
       " 15  0.653095  0.653571  0.648095  0.691905\n",
       " 16  0.086364  0.065909  0.077273  0.079545\n",
       " 17  0.045500  0.040500  0.045000  0.042000,\n",
       "            0         1         2         3\n",
       " 0   0.595455  0.650000  0.556364  0.613636\n",
       " 1   0.607077  0.596000  0.553538  0.548154\n",
       " 2   0.762500  0.775000  0.775000  0.775000\n",
       " 3   0.287234  0.289362  0.321277  0.287234\n",
       " 4   0.751333  0.740685  0.733982  0.732685\n",
       " 5   0.010811  0.005480  0.008108  0.005480\n",
       " 6   0.230392  0.243137  0.138592  0.231373\n",
       " 7   0.177056  0.205195  0.183333  0.169048\n",
       " 8   0.604762  0.661905  0.623810  0.690476\n",
       " 9   0.480041  0.493922  0.483489  0.476739\n",
       " 10  0.709603  0.709603  0.703651  0.723889\n",
       " 11  0.243300  0.239000  0.238850  0.246450\n",
       " 12  0.202353  0.158824  0.124118  0.150420\n",
       " 13  0.789962  0.791164  0.791298  0.794768\n",
       " 14  0.033126  0.033748  0.032193  0.032504\n",
       " 15  0.635238  0.610714  0.605952  0.654286\n",
       " 16  0.068182  0.047727  0.056818  0.059091\n",
       " 17  0.031000  0.029500  0.030500  0.030500]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['KNeighborsClassifier', 'DecisionTreeClassifier', 'GaussianNB'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(os.path.join('mean_ranks', '_'.join([str(percent), base_])+'.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 âœ…\n",
      "0.1 âœ…\n",
      "0.15 âœ…\n",
      "0.2 âœ…\n",
      "0.25 âœ…\n",
      "0.3 âœ…\n",
      "0.35 âœ…\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = {}\n",
    "\n",
    "for percent in percents_labeled:\n",
    "    curr_vals = base_filter_values()\n",
    "\n",
    "    base_dfs = list()\n",
    "    split_onto_base_estimators()\n",
    "    print(percent, end=' ')\n",
    "    for base, df in zip(base_estimators, base_dfs):\n",
    "        metric_vals = df.to_numpy()\n",
    "        result = autorank(df, alpha=0.05, verbose=False, approach='frequentist')\n",
    "        results[tuple((percent, base))] = result\n",
    "    print('âœ…')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reports for each percent and base estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(percent, base, report):\n",
    "    print(f'{GRN}> Percent labeled: {NC}', percent, f'\\n{GRN}> Base Estimator:  {NC}', base, end='\\n\\n')\n",
    "    create_report(report)\n",
    "    plot_stats(result)\n",
    "    plt.savefig(f'result_plots/{percent}_{base}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "keys_list = list(results.keys())\n",
    "print(len(keys_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32m> Percent labeled: \u001b[0m 0.05 \n",
      "\u001b[0;32m> Base Estimator:  \u001b[0m KNeighborsClassifier\n",
      "\n",
      "The statistical analysis was conducted for 4 populations with 18 paired samples.\n",
      "The family-wise significance level of the tests is alpha=0.050.\n",
      "We failed to reject the null hypothesis that the population is normal for all populations (minimal observed p-value=0.028). Therefore, we assume that all populations are normal.\n",
      "We applied Bartlett's test for homogeneity and failed to reject the null hypothesis (p=1.000) that the data is homoscedastic. Thus, we assume that our data is homoscedastic.\n",
      "Because we have more than two populations and all populations are normal and homoscedastic, we use repeated measures ANOVA as omnibus test to determine if there are any significant differences between the mean values of the populations. If the results of the ANOVA test are significant, we use the post-hoc Tukey HSD test to infer which differences are significant. We report the mean value (M) and the standard deviation (SD) for each population. Populations are significantly different if their confidence intervals are not overlapping.\n",
      "We failed to reject the null hypothesis (p=0.730) of the repeated measures ANOVA that there is a difference between the mean values of the populations KNeighborsClassifier:LSSm (M=0.344+-0.130, SD=0.298), KNeighborsClassifier:ENN (M=0.343+-0.130, SD=0.296), KNeighborsClassifier:base (M=0.348+-0.130, SD=0.292), and KNeighborsClassifier:ENANE (M=0.355+-0.130, SD=0.295). Therefore, we assume that there is no statistically significant difference between the mean values of the populations.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "result is not significant and results of the plot may be misleading. If you want to create the plot regardless, use the allow_insignificant parameter to suppress this exception.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/danix/OneDrive - Universidad de Burgos/Documentos/Ingenieria Informatica/4o curso/Semisupervised-learning-and-instance-selection-methods/experimentation/rank_statistics.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danix/OneDrive%20-%20Universidad%20de%20Burgos/Documentos/Ingenieria%20Informatica/4o%20curso/Semisupervised-learning-and-instance-selection-methods/experimentation/rank_statistics.ipynb#ch0000024?line=0'>1</a>\u001b[0m percent, base \u001b[39m=\u001b[39m keys_list[\u001b[39m0\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danix/OneDrive%20-%20Universidad%20de%20Burgos/Documentos/Ingenieria%20Informatica/4o%20curso/Semisupervised-learning-and-instance-selection-methods/experimentation/rank_statistics.ipynb#ch0000024?line=1'>2</a>\u001b[0m print_report(percent, base, results[(percent, base)])\n",
      "\u001b[1;32m/Users/danix/OneDrive - Universidad de Burgos/Documentos/Ingenieria Informatica/4o curso/Semisupervised-learning-and-instance-selection-methods/experimentation/rank_statistics.ipynb Cell 23'\u001b[0m in \u001b[0;36mprint_report\u001b[0;34m(percent, base, report)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danix/OneDrive%20-%20Universidad%20de%20Burgos/Documentos/Ingenieria%20Informatica/4o%20curso/Semisupervised-learning-and-instance-selection-methods/experimentation/rank_statistics.ipynb#ch0000022?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mGRN\u001b[39m}\u001b[39;00m\u001b[39m> Percent labeled: \u001b[39m\u001b[39m{\u001b[39;00mNC\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, percent, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mGRN\u001b[39m}\u001b[39;00m\u001b[39m> Base Estimator:  \u001b[39m\u001b[39m{\u001b[39;00mNC\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, base, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danix/OneDrive%20-%20Universidad%20de%20Burgos/Documentos/Ingenieria%20Informatica/4o%20curso/Semisupervised-learning-and-instance-selection-methods/experimentation/rank_statistics.ipynb#ch0000022?line=2'>3</a>\u001b[0m create_report(report)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danix/OneDrive%20-%20Universidad%20de%20Burgos/Documentos/Ingenieria%20Informatica/4o%20curso/Semisupervised-learning-and-instance-selection-methods/experimentation/rank_statistics.ipynb#ch0000022?line=3'>4</a>\u001b[0m plot_stats(result)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danix/OneDrive%20-%20Universidad%20de%20Burgos/Documentos/Ingenieria%20Informatica/4o%20curso/Semisupervised-learning-and-instance-selection-methods/experimentation/rank_statistics.ipynb#ch0000022?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39msavefig(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mresult_plots/\u001b[39m\u001b[39m{\u001b[39;00mpercent\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mbase\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IS-SSL/lib/python3.9/site-packages/autorank/autorank.py:321\u001b[0m, in \u001b[0;36mplot_stats\u001b[0;34m(result, allow_insignificant, ax, width)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/IS-SSL/lib/python3.9/site-packages/autorank/autorank.py?line=317'>318</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mploting results of bayesian analysis not yet supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/IS-SSL/lib/python3.9/site-packages/autorank/autorank.py?line=319'>320</a>\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mpvalue \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m result\u001b[39m.\u001b[39malpha \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_insignificant:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/IS-SSL/lib/python3.9/site-packages/autorank/autorank.py?line=320'>321</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/IS-SSL/lib/python3.9/site-packages/autorank/autorank.py?line=321'>322</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresult is not significant and results of the plot may be misleading. If you want to create the plot \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/IS-SSL/lib/python3.9/site-packages/autorank/autorank.py?line=322'>323</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mregardless, use the allow_insignificant parameter to suppress this exception.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/IS-SSL/lib/python3.9/site-packages/autorank/autorank.py?line=324'>325</a>\u001b[0m \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m width \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/IS-SSL/lib/python3.9/site-packages/autorank/autorank.py?line=325'>326</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39mwidth may be ignored because ax is defined.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: result is not significant and results of the plot may be misleading. If you want to create the plot regardless, use the allow_insignificant parameter to suppress this exception."
     ]
    }
   ],
   "source": [
    "percent, base = keys_list[0]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[1]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[2]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[3]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[4]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[5]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[6]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[7]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[8]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[9]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[10]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[11]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[12]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[13]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[14]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[15]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[16]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[17]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[18]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[19]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent, base = keys_list[20]\n",
    "print_report(percent, base, results[(percent, base)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.array([[100, 100, 50],\n",
    "              [90,100,100],\n",
    "              [100,100,100],\n",
    "              [100,99,98],\n",
    "              [50,51,52]\n",
    "             ])\n",
    "df_ranks = pd.DataFrame(h)\n",
    "print(scipy.stats.rankdata(-h, axis=1).mean(axis=0))\n",
    "\n",
    "print(df_ranks.rank(ascending=False, method=\"average\", axis=1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddbf58beb0ceb3f28487c8a8d7192b043471fe4d33849d20361912ddb46861bb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('IS-SSL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
